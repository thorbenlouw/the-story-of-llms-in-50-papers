# Plain‑Language Posts Index

This folder contains the course’s plain‑language posts, ordered to match the
syllabus. Each entry links to an explainer that connects the paper to the
course narrative with accessible analogies and context.

## Phase I: The Transformer Foundations

- [01 — Attention Is All You Need](01-attention-is-all-you-need-vaswani-2017.md)
- [02 — Recurrent Neural Network Regularization](02-rnn-regularization-zaremba-2014.md)
- [03 — Improving Language Understanding (GPT‑1)](03-improving-language-understanding-gpt1-radford-2018.md)
- [04 — BERT: Bidirectional Pre‑Training](04-bert-pretraining-devlin-2018.md)
- [05 — T5: Text‑to‑Text Transfer](05-t5-unified-text-to-text-raffel-2019.md)
- [06 — RoFormer: Rotary Positional Embeddings](06-roformer-enhanced-transformer-su-2021.md)

## Phase II: Scaling and Efficiency

- [07 — Scaling Laws for Language Models](07-scaling-laws-neural-language-models-kaplan-2020.md)
- [08 — Training Compute‑Optimal LLMs (Chinchilla)](08-training-compute-optimal-llm-hoffmann-2022.md)
- [09 — Switch Transformers (Mixture‑of‑Experts)](09-switch-transformers-moe-fedus-2021.md)
- [10 — LLaMA 2: Open Foundation + Chat](10-llama-2-open-foundation-touvron-2023.md)
- [11 — FlashAttention: IO‑Aware Exact Attention](11-flashattention-fast-io-aware-dao-2022.md)
- [12 — GPTQ: Accurate Post‑Training Quantisation](12-gptq-accurate-post-training-quant-frantar-2022.md)

## Phase III: Alignment, Evaluation, and Safety

- [13 — FLAN: Instruction Tuning](13-flan-finetuned-zero-shot-wei-2021.md)
- [14 — Emergent Abilities of LLMs](14-emergent-abilities-llm-wei-2022.md)
- [15 — HELM: Holistic Evaluation](15-helm-holistic-evaluation-liang-2022.md)
- [16 — BIG‑bench: Community Capability Suite](16-big-bench-beyond-imitation-game-srivastava-2022.md)
- [17 — InstructGPT: RLHF For Following Instructions](17-instructgpt-training-instructions-ouyang-2022.md)
- [18 — Deep RL From Human Preferences (2017)](18-deep-rl-human-preferences-christiano-2017.md)
- [19 — DPO: Direct Preference Optimisation](19-dpo-direct-preference-optimization-rafailov-2023.md)
- [20 — Constitutional AI: Harmlessness From AI Feedback](20-constitutional-ai-harmlessness-bai-2022.md)
- [21 — TruthfulQA: Measuring Imitative Falsehoods](21-truthfulqa-measuring-falsehoods-lin-2021.md)
- [22 — Measuring Faithfulness in Chain‑of‑Thought](22-measuring-faithfulness-cot-lanham-2023.md)

Tip: Each post ends with a “See Also” section that links to the previous and
next paper to keep you oriented as you read through the series.

